"""Generate personalized outreach messages and extract profile metadata"""

import re
from typing import Dict
from llm_client import query_llama


def parse_profile_metadata(title: str, snippet: str) -> Dict[str, str]:
    metadata = {
        "name": "",
        "current_role": "",
        "company": "",
        "experience_level": "Unknown",
        "key_skills": []
    }

    # Split common delimiters to extract name and the rest (role/company)
    parts = re.split(r"\s*[-|•—|\\|]\s*", title)
    if parts:
        metadata["name"] = parts[0].strip()

    remainder = " ".join(parts[1:]).strip() if len(parts) > 1 else ""

    # Try to extract role and company from the remainder
    role = ""
    company = ""

    if remainder:
        low = remainder.lower()
        if " at " in low:
            # e.g., "Senior PM at Acme Corp"
            rparts = re.split(r"\s+at\s+", remainder, flags=re.IGNORECASE)
            role = rparts[0].strip()
            company = rparts[1].strip() if len(rparts) > 1 else ""
        elif "@" in remainder:
            rparts = remainder.split("@", 1)
            role = rparts[0].strip()
            company = rparts[1].strip()
        elif "(" in remainder and ")" in remainder:
            # e.g., "Product Manager (Acme Corp)"
            m = re.search(r"\(([^)]+)\)", remainder)
            if m:
                company = m.group(1).strip()
            role = re.sub(r"\([^)]*\)", "", remainder).strip()
        elif "," in remainder:
            rparts = remainder.split(",", 1)
            role = rparts[0].strip()
            company = rparts[1].strip()
        else:
            role = remainder

    # As a fallback, try to find company mentions in the snippet
    if not company:
        m2 = re.search(r"\b(at|works at|company[:\s])\s+([A-Z][\w&\.\- ]{2,})", snippet, flags=re.IGNORECASE)
        if m2:
            company = m2.group(2).strip()

    metadata["current_role"] = role
    metadata["company"] = company

    snippet_lower = (snippet + title).lower()
    if any(word in snippet_lower for word in ["principal", "director", "vp", "head of", "chief", "c-level"]):
        metadata["experience_level"] = "Executive"
    elif any(word in snippet_lower for word in ["senior", "lead", "staff", "principal", "manager"]):
        metadata["experience_level"] = "Senior"
    elif any(word in snippet_lower for word in ["mid-level", "3-5 years", "4+ years", "5+ years"]):
        metadata["experience_level"] = "Mid-Level"
    elif any(word in snippet_lower for word in ["junior", "1-2 years", "2-3 years", "entry", "graduate"]):
        metadata["experience_level"] = "Junior"

    skill_keywords = [
        "product management", "growth", "b2b", "b2c", "saas", "enterprise",
        "strategy", "analytics", "data", "customer", "market", "launch",
        "monetization", "pricing", "fundraising", "leadership", "innovation"
    ]

    combined_text = (snippet + title).lower()
    found_skills = [skill for skill in skill_keywords if skill in combined_text]
    metadata["key_skills"] = list(set(found_skills))[:5]

    return metadata


def sanitize_model_output(text: str) -> str:
    """
    Remove common assistant preambles, notes, and extraneous meta text from model outputs.
    Returns a cleaned, copy-paste-ready message (first up to ~6 sentences).
    """
    if not text:
        return ""

    # Normalize and trim
    text = text.strip()

    # Remove leading preamble patterns like "Here is the LinkedIn outreach message:" etc.
    # Prefer longer alternatives (e.g., "here is") before shorter ones ("here").
    text = re.sub(
        r"^\s*(?:here\s+is|here(?:'s)?|outputted|output|result|generated|assistant)[:\s\-–—]*"
        r"(?:the\s+)?(?:generated\s+)?(?:linkedin|linked ?in)?\s*(?:outreach\s*)?(?:message|messages|text)?[:\-\–\—\s]*",
        "",
        text,
        flags=re.IGNORECASE,
    )

    # Remove leading phrases like "a LinkedIn outreach message based on the provided context:"
    text = re.sub(
        r"^\s*a\s+(?:the\s+)?(?:linkedin|linked ?in)\s*(?:outreach\s*)?(?:message|messages)(?:\s+based\s+on[^:]{0,100})?[:\-\s]*",
        "",
        text,
        flags=re.IGNORECASE,
    )

    # Remove parenthetical or bracketed notes like "(Note: ...)", "[Generated by AI]"
    text = re.sub(r"\(\s*(?:note|generated|powered by|created by)[^)]*\)", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\[\s*(?:note|generated|powered by|created by)[^\]]*\]", "", text, flags=re.IGNORECASE)

    # Remove assistant labels like "Assistant:" or "AI:"
    text = re.sub(r"^\s*(assistant|ai|model)[:\-\s]+\s*", "", text, flags=re.IGNORECASE)

    # Remove leading bullets or numbering
    text = re.sub(r"^\s*[\-\*\•\d\)\.]+\s*", "", text)

    # Drop lines that are obviously meta/explanatory
    lines = [ln for ln in text.splitlines() if not re.match(r"^\s*(note|p\.s|ps|meta|explanation|explanatory|context)[:\-\)]", ln, flags=re.IGNORECASE)]
    text = "\n".join(lines).strip()

    # Keep up to ~6 sentences to avoid trailing long explanations
    sentences = re.split(r'(?<=[\.\?\!])\s+', text)
    if len(sentences) > 6:
        sentences = sentences[:6]
    cleaned = " ".join(sentences).strip()

    # Final trim of stray quotes/backticks
    cleaned = cleaned.strip(' "\'`')

    return cleaned


def _base_prompt(
    user_background: str,
    profile: Dict,
    relationship_goal: str,
    value_prop: str,
    tone: str,
    cta_type: str,
    interests: str,
    problem_solving: str,
    achievements: str,
    personalization_level: int,
    mention_mutual: bool,
):
    personalization_hint = {
        1: "Keep very brief and generic",
        2: "Basic personalization",
        3: "Good balance of personal and concise",
        4: "Deep personalization with multiple references",
        5: "Highly personalized, detailed, reference their specific achievements"
    }

    prompt = f"""Generate a LinkedIn outreach message based on the context below.

CONTEXT:
Your Background: {user_background or 'Not specified'}
Value Proposition: {value_prop or 'Not specified'}
Problem You Solve: {problem_solving or 'Not specified'}
Achievements: {achievements or 'Not specified'}
Interests: {interests or 'Not specified'}

TARGET:
- Name: {profile.get('name', 'Professional')}
- Role: {profile.get('current_role', 'Unknown')}
- Company: {profile.get('company', 'Unknown')}
- Experience Level: {profile.get('experience_level', 'Unknown')}
- Key Skills: {', '.join(profile.get('key_skills', []))}
- Profile Summary: {profile.get('snippet', '')}

OUTREACH PARAMETERS:
- Goal: {relationship_goal}
- Tone: {tone}
- Call-to-Action: {cta_type}
- Personalization Depth: {personalization_hint.get(personalization_level, 'Standard')}
- Mention Mutual Connections: {'Yes' if mention_mutual else 'No'}

GUIDELINES:
- Write a concise, professional LinkedIn message (2-4 sentences max).
- Reference something SPECIFIC from the profile or their role.
- Lead with value/relevance, NOT with what you want.
- Include a clear but soft CTA at the end (e.g., "Would love to connect" or "Let's chat sometime").
- Match the requested tone and personalization depth.
- Output ONLY the message itself, no preamble, meta-text, or explanations.
- Do NOT include phrases like "Here's a message", "Let me know if...", or meta commentary.
- Make it ready to copy-paste directly into LinkedIn DMs without editing.
- Be authentic and conversational, not robotic.
"""
    return prompt


def _variant_instructions(variant: str) -> str:
    if variant == "short":
        return "Output a very short message (1-2 sentences). Keep it concise and direct."
    if variant == "medium":
        return "Output a medium-length message (2-4 sentences). Balanced personalization."
    if variant == "ultra":
        return "Output an ultra-personalized message (3-6 sentences). Include multiple profile-specific references and a clear but gentle CTA."
    return ""


def generate_outreach_variants(
    user_background: str,
    profile: Dict,
    relationship_goal: str = "Network & Build Relationship",
    value_prop: str = "",
    tone: str = "Professional & Friendly",
    cta_type: str = "Coffee/Chat Request",
    interests: str = "",
    problem_solving: str = "",
    achievements: str = "",
    personalization_level: int = 3,
    mention_mutual: bool = True,
):
    """
    Return 3 variants: short, medium, ultra.
    Falls back to simple templates if LLM fails.
    """
    base = _base_prompt(
        user_background,
        profile,
        relationship_goal,
        value_prop,
        tone,
        cta_type,
        interests,
        problem_solving,
        achievements,
        personalization_level,
        mention_mutual,
    )

    variants = {}
    for key in ("short", "medium", "ultra"):
        # Add a compact few-shot example to encourage variability and strict use
        # of the provided profile fields. Keep examples short so prompts remain
        # concise.
        examples = (
            "\n\nEXAMPLES:\n"
            "Profile: - Name: Alice Nguyen - Role: Senior PM at FinPay - Key Skills: payments, growth\n"
            "Medium: Hi Alice, I loved your work leading payments product at FinPay — especially the growth experiments you led. I help product teams move faster with better analytics; would you be open to a 20-min chat to compare notes?\n\n"
            "Profile: - Name: Ben Carter - Role: VP Engineering at InfraWorks - Key Skills: cloud, infra\n"
            "Medium: Hi Ben, your leadership at InfraWorks on cloud reliability caught my eye. I work on tooling that improves deploy velocity; would you be open to a quick call to share perspectives?\n"
        )

        prompt = base + examples + "\n" + _variant_instructions(key) + "\n\nRespond with ONLY the message text."
        try:
            text = query_llama(prompt)
            if not text or text.strip() == "":
                raise RuntimeError("Empty response")
            text = sanitize_model_output(text)
            variants[key] = text
        except Exception:
            # fallback template generation (used when LLM is unavailable or errors)
            name = profile.get("name", "there")
            role = profile.get("current_role", "")
            comp = profile.get("company", "")
            skills = profile.get('key_skills', [])
            skill_str = ', '.join(skills[:3]) if skills else ''

            # Natural CTA phrasing mapping to avoid awkward literal lowercasing
            cta_map = {
                'coffee/chat request': 'grab a 15–20min coffee/chat',
                'demo request': 'schedule a short demo',
                'meeting proposal': 'schedule a brief meeting',
                'quick question': 'ask a quick question',
            }
            cta_key = (cta_type or '').lower()
            cta_phrase = cta_map.get(cta_key, f'connect or {cta_key}')

            if key == "short":
                variants[key] = (
                    f"Hi {name.split()[0] if name else 'there'},\n\nQuick note — your work as {role or 'a professional'}"
                    f"{(' at ' + comp) if comp else ''} stood out. {value_prop or ''} {cta_phrase}?\n\nThanks!"
                )
            elif key == "medium":
                variants[key] = (
                    f"Hi {name.split()[0] if name else 'there'},\n\nI came across your work as {role}"
                    f"{(' at ' + comp) if comp else ''}. {value_prop or ''} I’d love to {cta_phrase} to learn about your experience and share a quick idea.\n\nBest,\n[Your Name]"
                )
            else:
                variants[key] = (
                    f"Hi {name.split()[0] if name else 'there'},\n\nI was impressed by your background as {role}"
                    f"{(' at ' + comp) if comp else ''}{(f' — experience with {skill_str}' ) if skill_str else ''}. "
                    f"{value_prop or ''} Would you be open to {cta_phrase} to explore this?\n\nThanks,\n[Your Name]"
                )
    return variants


def generate_outreach_message(
    user_background: str,
    profile: Dict,
    relationship_goal: str = "Network & Build Relationship",
    value_prop: str = "",
    tone: str = "Professional & Friendly",
    cta_type: str = "Coffee/Chat Request",
    interests: str = "",
    problem_solving: str = "",
    achievements: str = "",
    personalization_level: int = 3,
    mention_mutual: bool = True,
):
    """
    Backwards-compatible: returns the medium variant by default.
    """
    variants = generate_outreach_variants(
        user_background=user_background,
        profile=profile,
        relationship_goal=relationship_goal,
        value_prop=value_prop,
        tone=tone,
        cta_type=cta_type,
        interests=interests,
        problem_solving=problem_solving,
        achievements=achievements,
        personalization_level=personalization_level,
        mention_mutual=mention_mutual,
    )
    return variants.get("medium", next(iter(variants.values())))
